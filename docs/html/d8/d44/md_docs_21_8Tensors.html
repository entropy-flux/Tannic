<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tannic: Tensors</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen-awesome.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tannic
   </div>
   <div id="projectbrief">A C++ Tensor Library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('d8/d44/md_docs_21_8Tensors.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Tensors</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="autotoc_md52"></a> </p>
<h1><a class="anchor" id="autotoc_md53"></a>
Introduction</h1>
<p>The tensor class is the main data structure of the library. It is basically an intention of a computation and it's coordinates can be seen as a multidimensional array. Tensors in this library are not templated, while this have a minimal performance penalty, it's not something you are not already paying when you using torch or jax, the easy of use simply outweights some minimal performance gain that can be obtained from making the tensors templated.</p>
<p>Having templated tensors means that a <code>Tensor&lt;int&gt;</code> and a <code>Tensor&lt;float&gt;</code> are different classes, while in tannic you only have a single <code>Tensor</code> class where dtype is explicitly passed as argument. This simplifies a lot the development of machine learning models that needs to support several dtypes. You can see what I'm talking about in this examples:</p>
<ul>
<li>A simple <a href="https://github.com/entropy-flux/cnn-server-example/blob/main/models/cnn.hpp">CNN</a> (convolutional neural network) for mnist digit recognition.</li>
<li>A simple <a href="https://github.com/entropy-flux/vit-server-example/blob/main/model/vit.hpp">ViT</a> (vision transformer) for classification tasks</li>
<li>A <a href="https://github.com/entropy-flux/llama3-server-example/blob/main/include/llama3.hpp">LLaMa3</a> transformer implementation, working for text completion.</li>
</ul>
<p>As you may see, those implementations are just as clean (if not cleaner) than their Python counterparts, with no template metaprogramming required. While I use neural networks as examples, this library is not limited to that domain. In fact, none of the neural network primitives you saw in the examples are implemented directly in the tensor library; instead, they exist as an <a href="https://github.com/entropy-flux/Tannic-NN">external nn library</a> built on top of it. This approach lays the groundwork for building a complete ecosystem for machine learning and physics simulations, not only neural networks.</p>
<h1><a class="anchor" id="autotoc_md54"></a>
Tensor initialization</h1>
<p>This library provides two convenient ways to construct and initialize tensors. These range from implicit C++ brace-initializer syntax (used for readability in small examples) to explicit initialization (recommended when specifying dtype, shape, or device explicitly). Tensors also can be used uninitialized, and initialization will happen on the first use by default on host.</p>
<p>More initialization methods will be added soon, ranging from statistical distributions to widely used initialization patterns.</p>
<h2><a class="anchor" id="autotoc_md55"></a>
1. Implicit Initialization</h2>
<p>Tensors can be directly constructed using nested brace lists. The nesting depth determines the rank (dimensionality) of the tensor, and the innermost values define the elements.</p>
<h3><a class="anchor" id="autotoc_md56"></a>
Example</h3>
<div class="fragment"><div class="line">Tensor A = {1,2,3,4,5};</div>
<div class="line"> </div>
<div class="line">Tensor B = {{</div>
<div class="line">    1.0f, 2.0f, 3.0f}, </div>
<div class="line">    {4.0f, 5.0f, 6.0f}</div>
<div class="line">}; </div>
<div class="line"> </div>
<div class="line">Tensor C = {</div>
<div class="line">    {{1.0, 2.0, 3.0}, {4.0, 5.0, 6.0}},</div>
<div class="line">    {{1.0, 2.0, 3.0}, {4.0, 5.0, 6.0}}</div>
<div class="line">};</div>
<div class="line"> </div>
<div class="line">std::cout &lt;&lt; A &lt;&lt; std::endl; <span class="comment">// int tensor</span></div>
<div class="line">std::cout &lt;&lt; B &lt;&lt; std::endl; <span class="comment">// float tensor</span></div>
<div class="line">std::cout &lt;&lt; C &lt;&lt; std::endl; <span class="comment">// double tensor</span></div>
</div><!-- fragment --><p><b>Note</b>: Implicit initialization infers dtype from the initializer list (e.g., int, float, double). If consistent typing or device placement is required, use explicit initialization. Be careful with this.</p>
<h3><a class="anchor" id="autotoc_md57"></a>
2. Explicit initialization</h3>
<p>Explicit initialization is useful when you need to set dtype, shape, or device precisely. Initialization with initializer list will be more flexible here since the elements of the initializer list will be casted automatically to the dtype of the tensor. For example you can initialize a float tensor with an int initializer list without issues.</p>
<h3><a class="anchor" id="autotoc_md58"></a>
Example</h3>
<div class="fragment"><div class="line">Tensor X(bfloat16, {3}); X.initialize({1, 2, 3}); <span class="comment">// integers will be casted to floats here automatically</span></div>
<div class="line">                                                  <span class="comment">// don&#39;t have to worry about the type of the initializer list.</span></div>
<div class="line"> </div>
<div class="line">Tensor Y(float16, {2, 3}); Y.initialize({         <span class="comment">// Here you are passing doubles to the tensor but they will be</span></div>
<div class="line">    {1.2, 2.4, 3.1},                              <span class="comment">// automatically casted to float16 type. You</span></div>
<div class="line">    {4.3, 5.6, 6.3}                                    </div>
<div class="line">});</div>
<div class="line"> </div>
<div class="line">Tensor Z(int8, {2, 2, 2}); Z.initialize({</div>
<div class="line">    {</div>
<div class="line">        {1, 2},</div>
<div class="line">        {3, 4}</div>
<div class="line">    },</div>
<div class="line">    {</div>
<div class="line">        {5, 6},</div>
<div class="line">        {7, 8}</div>
<div class="line">    }</div>
<div class="line">});</div>
<div class="line"> </div>
<div class="line">std::cout &lt;&lt; X &lt;&lt; std::endl;</div>
<div class="line">std::cout &lt;&lt; Y &lt;&lt; std::endl;</div>
<div class="line">std::cout &lt;&lt; Z &lt;&lt; std::endl;</div>
</div><!-- fragment --><p>In the prior example an object of type shape was constructed implicitly when calling the tensor constructor. You can pass shape or even strides explicitly to tensor constructors when building a tensor:</p>
<div class="fragment"><div class="line">Tensor Y(float64, Shape(2, 3)); Y.initialize({</div>
<div class="line">    {1, 2, 3},</div>
<div class="line">    {4, 5, 6}</div>
<div class="line">});</div>
<div class="line"> </div>
<div class="line">std::cout &lt;&lt; Y &lt;&lt; std::endl;</div>
<div class="line"> </div>
<div class="line"><span class="keyword">constexpr</span> Shape shape(2, 3);    </div>
<div class="line"><span class="keyword">constexpr</span> Strides strides(3, 1); <span class="comment">// shapes and strides are constexpr friendly. </span></div>
<div class="line"> </div>
<div class="line">Tensor Z(int32, shape, strides); Z.initialize({</div>
<div class="line">    {1, 2, 3},</div>
<div class="line">    {4, 5, 6}</div>
<div class="line">});</div>
<div class="line"> </div>
<div class="line">std::cout &lt;&lt; shape &lt;&lt; strides &lt;&lt; std::endl; <span class="comment">// they are also printable.</span></div>
<div class="line">std::cout &lt;&lt; Z &lt;&lt; std::endl;</div>
</div><!-- fragment --><p>Tensors can be allocated directly on a specified device to allow harware aceleration. Tannic have only CUDA support for now, however Host-Device compuational model is not CUDA specific and can be extended to other vendors.</p>
<h3><a class="anchor" id="autotoc_md59"></a>
Example</h3>
<div class="fragment"><div class="line">Tensor X(float16, {3}); X.initialize({1, 2, 3}, Device()); <span class="comment">// defaults to 0. </span></div>
<div class="line">std::cout &lt;&lt; X &lt;&lt; std::endl;</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md60"></a>
Other initialization methods.</h2>
<p>There are more ways to initialize tensors, but they are not documented here because their usage may change, they are from internal usage or are out of the scope of this section, like for example how tensors are built when they come serialized from network.</p>
<h2><a class="anchor" id="autotoc_md61"></a>
3. Assignment</h2>
<p>After creation, tensors support element-wise and slice assignment. If they weren't initialized before asignment they will be initialized by default on host. Unassigned elements remain uninitialized until written to.</p>
<div class="fragment"><div class="line">Tensor X(bfloat16, {2,2});   </div>
<div class="line">X[0, range{0,-1}] = 1; </div>
<div class="line">X[1,0] = 3;</div>
<div class="line">X[1][1] = 4; </div>
<div class="line">std::cout &lt;&lt; X &lt;&lt; std::endl;</div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line">Tensor Y(float64, {2,2}); Y.initialize(Device());  </div>
<div class="line">Y[{0,-1}] = 1; </div>
<div class="line">std::cout &lt;&lt; Y &lt;&lt; std::endl; </div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md62"></a>
4. Supported dtypes.</h2>
<p>The library provides a fixed set of supported data types. They are defined as a plain C-compatible enum, so they can be safely used in both C and C++ code. In C++, all dtypes are available under the tannic namespace. The following list of dtypes is supported.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Library dtype   </th><th class="markdownTableHeadNone">Native C/C++ equivalent    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>any</code>   </td><td class="markdownTableBodyNone">(placeholder, no fixed type)    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>boolean</code>   </td><td class="markdownTableBodyNone"><code>bool</code> (bit packed)    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>int8</code>   </td><td class="markdownTableBodyNone"><code>int8_t</code>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>int16</code>   </td><td class="markdownTableBodyNone"><code>int16_t</code>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>int32</code>   </td><td class="markdownTableBodyNone"><code>int32_t</code>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>int64</code>   </td><td class="markdownTableBodyNone"><code>int64_t</code>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>float16</code>   </td><td class="markdownTableBodyNone">compiler-specific    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>bfloat16</code>   </td><td class="markdownTableBodyNone">compiler-specific    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>float32</code>   </td><td class="markdownTableBodyNone"><code>float</code>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>float64</code>   </td><td class="markdownTableBodyNone"><code>double</code>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>complex64</code>   </td><td class="markdownTableBodyNone"><code>std::complex&lt;float&gt;</code>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>complex128</code>   </td><td class="markdownTableBodyNone"><code>std::complex&lt;double&gt;</code>   </td></tr>
</table>
<p>Expect to have <code>int4</code> and <code>complex32</code> dtypes support soon.</p>
<h2><a class="anchor" id="autotoc_md63"></a>
5. Copy semantics</h2>
<p>The Tensor class is shallow copiable, this means that is cheap to copy tensors, and copied tensors will reference to the same underlying storage, for example:</p>
<h3><a class="anchor" id="autotoc_md64"></a>
Example</h3>
<div class="fragment"><div class="line">Tensor X = {1, 2, 3, 4, 5};</div>
<div class="line">Tensor Y = X;         <span class="comment">// Cheap copy,  </span></div>
<div class="line">Tensor Z = Y[{1, 3}]; <span class="comment">// Cheap view</span></div>
<div class="line">Z[{0, -1}] = 5;       <span class="comment">// Will modify X tensor.</span></div>
<div class="line">std::cout &lt;&lt; X &lt;&lt; std::endl; </div>
</div><!-- fragment --><p>Will print a modified tensor.</p>
<div class="fragment"><div class="line">Tensor([1, 5, 5, 4, 5], dtype=int32, shape=(5))</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
