\chapter{Tensors}
\hypertarget{md_docs_21_8Tensors}{}\label{md_docs_21_8Tensors}\index{Tensors@{Tensors}}
\label{md_docs_21_8Tensors_autotoc_md52}%
\Hypertarget{md_docs_21_8Tensors_autotoc_md52}%
 \hypertarget{md_docs_21_8Tensors_autotoc_md53}{}\doxysection{\texorpdfstring{Introduction}{Introduction}}\label{md_docs_21_8Tensors_autotoc_md53}
The tensor class is the main data structure of the library. It is basically an intention of a computation and it\textquotesingle{}s coordinates can be seen as a multidimensional array. Tensors in this library are not templated, while this have a minimal performance penalty, it\textquotesingle{}s not something you are not already paying when you using torch or jax, the easy of use simply outweights some minimal performance gain that can be obtained from making the tensors templated.

Having templated tensors means that a {\ttfamily Tensor\texorpdfstring{$<$}{<}int\texorpdfstring{$>$}{>}} and a {\ttfamily Tensor\texorpdfstring{$<$}{<}float\texorpdfstring{$>$}{>}} are different classes, while in tannic you only have a single {\ttfamily Tensor} class where dtype is explicitly passed as argument. This simplifies a lot the development of machine learning models that needs to support several dtypes. You can see what I\textquotesingle{}m talking about in this examples\+:


\begin{DoxyItemize}
\item A simple \href{https://github.com/entropy-flux/cnn-server-example/blob/main/models/cnn.hpp}{\texttt{ CNN}} (convolutional neural network) for mnist digit recognition.
\item A simple \href{https://github.com/entropy-flux/vit-server-example/blob/main/model/vit.hpp}{\texttt{ ViT}} (vision transformer) for classification tasks
\item A \href{https://github.com/entropy-flux/llama3-server-example/blob/main/include/llama3.hpp}{\texttt{ LLa\+Ma3}} transformer implementation, working for text completion.
\end{DoxyItemize}

As you may see, those implementations are just as clean (if not cleaner) than their Python counterparts, with no template metaprogramming required. While I use neural networks as examples, this library is not limited to that domain. In fact, none of the neural network primitives you saw in the examples are implemented directly in the tensor library; instead, they exist as an \href{https://github.com/entropy-flux/Tannic-NN}{\texttt{ external nn library}} built on top of it. This approach lays the groundwork for building a complete ecosystem for machine learning and physics simulations, not only neural networks.\hypertarget{md_docs_21_8Tensors_autotoc_md54}{}\doxysection{\texorpdfstring{Tensor initialization}{Tensor initialization}}\label{md_docs_21_8Tensors_autotoc_md54}
This library provides two convenient ways to construct and initialize tensors. These range from implicit C++ brace-\/initializer syntax (used for readability in small examples) to explicit initialization (recommended when specifying dtype, shape, or device explicitly). Tensors also can be used uninitialized, and initialization will happen on the first use by default on host.

More initialization methods will be added soon, ranging from statistical distributions to widely used initialization patterns.\hypertarget{md_docs_21_8Tensors_autotoc_md55}{}\doxysubsection{\texorpdfstring{1. Implicit Initialization}{1. Implicit Initialization}}\label{md_docs_21_8Tensors_autotoc_md55}
Tensors can be directly constructed using nested brace lists. The nesting depth determines the rank (dimensionality) of the tensor, and the innermost values define the elements.\hypertarget{md_docs_21_8Tensors_autotoc_md56}{}\doxysubsubsection{\texorpdfstring{Example}{Example}}\label{md_docs_21_8Tensors_autotoc_md56}

\begin{DoxyCode}{0}
\DoxyCodeLine{Tensor\ A\ =\ \{1,2,3,4,5\};}
\DoxyCodeLine{}
\DoxyCodeLine{Tensor\ B\ =\ \{\{}
\DoxyCodeLine{\ \ \ \ 1.0f,\ 2.0f,\ 3.0f\},\ }
\DoxyCodeLine{\ \ \ \ \{4.0f,\ 5.0f,\ 6.0f\}}
\DoxyCodeLine{\};\ }
\DoxyCodeLine{}
\DoxyCodeLine{Tensor\ C\ =\ \{}
\DoxyCodeLine{\ \ \ \ \{\{1.0,\ 2.0,\ 3.0\},\ \{4.0,\ 5.0,\ 6.0\}\},}
\DoxyCodeLine{\ \ \ \ \{\{1.0,\ 2.0,\ 3.0\},\ \{4.0,\ 5.0,\ 6.0\}\}}
\DoxyCodeLine{\};}
\DoxyCodeLine{}
\DoxyCodeLine{std::cout\ <<\ A\ <<\ std::endl;\ \textcolor{comment}{//\ int\ tensor}}
\DoxyCodeLine{std::cout\ <<\ B\ <<\ std::endl;\ \textcolor{comment}{//\ float\ tensor}}
\DoxyCodeLine{std::cout\ <<\ C\ <<\ std::endl;\ \textcolor{comment}{//\ double\ tensor}}

\end{DoxyCode}


{\bfseries{Note}}\+: Implicit initialization infers dtype from the initializer list (e.\+g., int, float, double). If consistent typing or device placement is required, use explicit initialization. Be careful with this.\hypertarget{md_docs_21_8Tensors_autotoc_md57}{}\doxysubsubsection{\texorpdfstring{2. Explicit initialization}{2. Explicit initialization}}\label{md_docs_21_8Tensors_autotoc_md57}
Explicit initialization is useful when you need to set dtype, shape, or device precisely. Initialization with initializer list will be more flexible here since the elements of the initializer list will be casted automatically to the dtype of the tensor. For example you can initialize a float tensor with an int initializer list without issues.\hypertarget{md_docs_21_8Tensors_autotoc_md58}{}\doxysubsubsection{\texorpdfstring{Example}{Example}}\label{md_docs_21_8Tensors_autotoc_md58}

\begin{DoxyCode}{0}
\DoxyCodeLine{Tensor\ X(bfloat16,\ \{3\});\ X.initialize(\{1,\ 2,\ 3\});\ \textcolor{comment}{//\ integers\ will\ be\ casted\ to\ floats\ here\ automatically}}
\DoxyCodeLine{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{//\ don't\ have\ to\ worry\ about\ the\ type\ of\ the\ initializer\ list.}}
\DoxyCodeLine{}
\DoxyCodeLine{Tensor\ Y(float16,\ \{2,\ 3\});\ Y.initialize(\{\ \ \ \ \ \ \ \ \ \textcolor{comment}{//\ Here\ you\ are\ passing\ doubles\ to\ the\ tensor\ but\ they\ will\ be}}
\DoxyCodeLine{\ \ \ \ \{1.2,\ 2.4,\ 3.1\},\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{//\ automatically\ casted\ to\ float16\ type.\ You}}
\DoxyCodeLine{\ \ \ \ \{4.3,\ 5.6,\ 6.3\}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\DoxyCodeLine{\});}
\DoxyCodeLine{}
\DoxyCodeLine{Tensor\ Z(int8,\ \{2,\ 2,\ 2\});\ Z.initialize(\{}
\DoxyCodeLine{\ \ \ \ \{}
\DoxyCodeLine{\ \ \ \ \ \ \ \ \{1,\ 2\},}
\DoxyCodeLine{\ \ \ \ \ \ \ \ \{3,\ 4\}}
\DoxyCodeLine{\ \ \ \ \},}
\DoxyCodeLine{\ \ \ \ \{}
\DoxyCodeLine{\ \ \ \ \ \ \ \ \{5,\ 6\},}
\DoxyCodeLine{\ \ \ \ \ \ \ \ \{7,\ 8\}}
\DoxyCodeLine{\ \ \ \ \}}
\DoxyCodeLine{\});}
\DoxyCodeLine{}
\DoxyCodeLine{std::cout\ <<\ X\ <<\ std::endl;}
\DoxyCodeLine{std::cout\ <<\ Y\ <<\ std::endl;}
\DoxyCodeLine{std::cout\ <<\ Z\ <<\ std::endl;}

\end{DoxyCode}


In the prior example an object of type shape was constructed implicitly when calling the tensor constructor. You can pass shape or even strides explicitly to tensor constructors when building a tensor\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{Tensor\ Y(float64,\ Shape(2,\ 3));\ Y.initialize(\{}
\DoxyCodeLine{\ \ \ \ \{1,\ 2,\ 3\},}
\DoxyCodeLine{\ \ \ \ \{4,\ 5,\ 6\}}
\DoxyCodeLine{\});}
\DoxyCodeLine{}
\DoxyCodeLine{std::cout\ <<\ Y\ <<\ std::endl;}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{keyword}{constexpr}\ Shape\ shape(2,\ 3);\ \ \ \ }
\DoxyCodeLine{\textcolor{keyword}{constexpr}\ Strides\ strides(3,\ 1);\ \textcolor{comment}{//\ shapes\ and\ strides\ are\ constexpr\ friendly.\ }}
\DoxyCodeLine{}
\DoxyCodeLine{Tensor\ Z(int32,\ shape,\ strides);\ Z.initialize(\{}
\DoxyCodeLine{\ \ \ \ \{1,\ 2,\ 3\},}
\DoxyCodeLine{\ \ \ \ \{4,\ 5,\ 6\}}
\DoxyCodeLine{\});}
\DoxyCodeLine{}
\DoxyCodeLine{std::cout\ <<\ shape\ <<\ strides\ <<\ std::endl;\ \textcolor{comment}{//\ they\ are\ also\ printable.}}
\DoxyCodeLine{std::cout\ <<\ Z\ <<\ std::endl;}

\end{DoxyCode}


Tensors can be allocated directly on a specified device to allow harware aceleration. Tannic have only CUDA support for now, however Host-\/\+Device compuational model is not CUDA specific and can be extended to other vendors.\hypertarget{md_docs_21_8Tensors_autotoc_md59}{}\doxysubsubsection{\texorpdfstring{Example}{Example}}\label{md_docs_21_8Tensors_autotoc_md59}

\begin{DoxyCode}{0}
\DoxyCodeLine{Tensor\ X(float16,\ \{3\});\ X.initialize(\{1,\ 2,\ 3\},\ Device());\ \textcolor{comment}{//\ defaults\ to\ 0.\ }}
\DoxyCodeLine{std::cout\ <<\ X\ <<\ std::endl;}

\end{DoxyCode}
\hypertarget{md_docs_21_8Tensors_autotoc_md60}{}\doxysubsection{\texorpdfstring{Other initialization methods.}{Other initialization methods.}}\label{md_docs_21_8Tensors_autotoc_md60}
There are more ways to initialize tensors, but they are not documented here because their usage may change, they are from internal usage or are out of the scope of this section, like for example how tensors are built when they come serialized from network.\hypertarget{md_docs_21_8Tensors_autotoc_md61}{}\doxysubsection{\texorpdfstring{3. Assignment}{3. Assignment}}\label{md_docs_21_8Tensors_autotoc_md61}
After creation, tensors support element-\/wise and slice assignment. If they weren\textquotesingle{}t initialized before asignment they will be initialized by default on host. Unassigned elements remain uninitialized until written to.


\begin{DoxyCode}{0}
\DoxyCodeLine{Tensor\ X(bfloat16,\ \{2,2\});\ \ \ }
\DoxyCodeLine{X[0,\ \mbox{\hyperlink{namespacetannic_affef8090e8f7ba383c67e15135664024}{range}}\{0,-\/1\}]\ =\ 1;\ }
\DoxyCodeLine{X[1,0]\ =\ 3;}
\DoxyCodeLine{X[1][1]\ =\ 4;\ }
\DoxyCodeLine{std::cout\ <<\ X\ <<\ std::endl;}
\DoxyCodeLine{}
\DoxyCodeLine{}
\DoxyCodeLine{Tensor\ Y(float64,\ \{2,2\});\ Y.initialize(Device());\ \ }
\DoxyCodeLine{Y[\{0,-\/1\}]\ =\ 1;\ }
\DoxyCodeLine{std::cout\ <<\ Y\ <<\ std::endl;\ }

\end{DoxyCode}
\hypertarget{md_docs_21_8Tensors_autotoc_md62}{}\doxysubsection{\texorpdfstring{4. Supported dtypes.}{4. Supported dtypes.}}\label{md_docs_21_8Tensors_autotoc_md62}
The library provides a fixed set of supported data types. They are defined as a plain C-\/compatible enum, so they can be safely used in both C and C++ code. In C++, all dtypes are available under the tannic namespace. The following list of dtypes is supported.

\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{2}{|X[-1]}|}
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Library dtype   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Native C/\+C++ equivalent    }\\\cline{1-2}
\endfirsthead
\hline
\endfoot
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Library dtype   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Native C/\+C++ equivalent    }\\\cline{1-2}
\endhead
{\ttfamily any}   &(placeholder, no fixed type)    \\\cline{1-2}
{\ttfamily boolean}   &{\ttfamily bool} (bit packed)    \\\cline{1-2}
{\ttfamily int8}   &{\ttfamily int8\+\_\+t}    \\\cline{1-2}
{\ttfamily int16}   &{\ttfamily int16\+\_\+t}    \\\cline{1-2}
{\ttfamily int32}   &{\ttfamily int32\+\_\+t}    \\\cline{1-2}
{\ttfamily int64}   &{\ttfamily int64\+\_\+t}    \\\cline{1-2}
{\ttfamily float16}   &compiler-\/specific    \\\cline{1-2}
{\ttfamily bfloat16}   &compiler-\/specific    \\\cline{1-2}
{\ttfamily float32}   &{\ttfamily float}    \\\cline{1-2}
{\ttfamily float64}   &{\ttfamily double}    \\\cline{1-2}
{\ttfamily complex64}   &{\ttfamily std\+::complex\texorpdfstring{$<$}{<}float\texorpdfstring{$>$}{>}}    \\\cline{1-2}
{\ttfamily complex128}   &{\ttfamily std\+::complex\texorpdfstring{$<$}{<}double\texorpdfstring{$>$}{>}}   \\\cline{1-2}
\end{longtabu}


Expect to have {\ttfamily int4} and {\ttfamily complex32} dtypes support soon.\hypertarget{md_docs_21_8Tensors_autotoc_md63}{}\doxysubsection{\texorpdfstring{5. Copy semantics}{5. Copy semantics}}\label{md_docs_21_8Tensors_autotoc_md63}
The Tensor class is shallow copiable, this means that is cheap to copy tensors, and copied tensors will reference to the same underlying storage, for example\+:\hypertarget{md_docs_21_8Tensors_autotoc_md64}{}\doxysubsubsection{\texorpdfstring{Example}{Example}}\label{md_docs_21_8Tensors_autotoc_md64}

\begin{DoxyCode}{0}
\DoxyCodeLine{Tensor\ X\ =\ \{1,\ 2,\ 3,\ 4,\ 5\};}
\DoxyCodeLine{Tensor\ Y\ =\ X;\ \ \ \ \ \ \ \ \ \textcolor{comment}{//\ Cheap\ copy,\ \ }}
\DoxyCodeLine{Tensor\ Z\ =\ Y[\{1,\ 3\}];\ \textcolor{comment}{//\ Cheap\ view}}
\DoxyCodeLine{Z[\{0,\ -\/1\}]\ =\ 5;\ \ \ \ \ \ \ \textcolor{comment}{//\ Will\ modify\ X\ tensor.}}
\DoxyCodeLine{std::cout\ <<\ X\ <<\ std::endl;\ }

\end{DoxyCode}


Will print a modified tensor.


\begin{DoxyCode}{0}
\DoxyCodeLine{Tensor([1,\ 5,\ 5,\ 4,\ 5],\ dtype=int32,\ shape=(5))}

\end{DoxyCode}
 